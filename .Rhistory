bs(testing$age,df=3)
bs(testing$age,df=3)-predict(bsBasis,age=testing$age)
predict(bsBasis,age=testing$age)
a<-predict(bsBasis,age=testing$age)
a-baBasis
a-bsBasis
?bs
rm(list=ls())
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(spam$type, p=0.75, list=F)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M<-abs(cor(training[,-58]))
diag(M)<-0
which(M>0.8,arr.ind = T)
M
which(M>0.8,arr.ind = T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
?which
which(M>0.8,arr.ind = F)
which(M>0.8,arr.ind = T)
install.packages(c("BMA", "fields", "HistData", "lavaan", "mgcv", "packrat", "party", "plotrix", "RandomFields", "RandomFieldsUtils", "RMySQL", "RUnit", "spam", "stringi", "testthat", "xtable"))
x<-0.71*training$num415 + 0.71*training$num857
y<-0.71*training$num415 - 0.71*training$num857
plot(x,y)
?prcomp
library(caret)
data("faithful")
set.seed(333)
inTrain <- createDataPartition(faithful$waiting,p=0.5,list=F)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(train)
head(trainFaith)
plot(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col='blue')
lm1 <- lm(eruptions~waiting,data=faithful)
summary(lm1)
lines(trainFaith$waiting,lm1$fitted.values,lwd=3)
lines(trainFaith$waiting,lm1$fitted,lwd=3)
lm1$fitted.values
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col='blue')
lines(trainFaith$waiting,lm1$fitted,lwd=3)
lm1 <- lm(eruptions~waiting,data=trainFaith)
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1]+coef(lm1)[2]*80
newdata<-data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col='blue')
lines(trainFaith$waiting,predict(lm1),lwd=3)
predict(lm1)-lm1.fitted
predict(lm1)-lm1$fitted.values
plot(testFaith$waiting,testFaith$eruptions,pch=19,col='blue')
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
sqrt(sum((lm1$fitted.values-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1)-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval='prediction')
ord<-order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19)
matlines(testFaith$waiting[ord],pred1[ord,],type='l',col=c(1,2,2))
?order
ord
?matlines
modFit <- train(eruptions~waiting,data=trainFaith,method='lm')
summary(modFit$finalModel)
rm(list=ls())
library(IRLS)
library(ISLR)
library(caret)
library(ggplot2)
data(Wage)
Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(Wage$wage,p=0.7,list=F)
training<- Wage[inTrain,]
testing <- Wage[-inTrain,]
sim(training)
dim(training)
dim(testing)
featurePlot(x=training[,c('age','education','jobclass')],y=training$wage)
featurePlot(x=training[,c('age','education','jobclass')],y=training$wage,plot='pairs')
modFit<-train(wage~age+jobclass+education,method='lm',data=training)
finMod<-modFit$finalModel
print(modFit)
summary(finMod)
plot(finMod,1,pch=19,cex=0,5)
plot(finMod,1,pch=19,cex=0.5)
plot(finMod,1,pch=19,cex=0.5,col='#00000010')
qplot(finMod$fitted.values,finMod$residuals,colour=race,data=training)
pred<-predict(modFit,testing)
qplot(wage,pred,colour=year,data=testing)
version(caret)
caret
version('caret')
summary('caret')
summary(library('caret'))
library('caret')
caret()
?caret
??caret
rm(list = ls())
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
View(predictors)
adData <- data.frame(diagnosis,predictors)
adData
View(adData)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(training$Superplasticizer)
qplot(training$Superplasticizer,col=training$CompressiveStrength)
plot(training$Superplasticizer,training$CompressiveStrength)
plot(training$Superplasticizer,training$CompressiveStrength)
plot(training$Superplasticizer,training$CompressiveStrength)
plot(log(training$Superplasticizer+1))
plot(log10(training$Superplasticizer+1))
plot(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer))
hist(training$Superplasticizer)
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
training[,'IL']
View(training)
subset(training,'IL')
?subset
training[,IL_11:IL_8]
training[,'IL_11':'IL_8']
names(training)
IL<-training[,58:69]
preProcess(IL)
prcomp(IL)
prComp<-prcomp(IL)
diag(prComp)<-0
prComp$sdev
prComp$sdev/sum(prComp$sdev)
preProc<-preProcess(IL,method='pca',thresh=0.9,outcome = training$diagnosis)
preProc$rotation
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL<-training[,58:69]
IL$diagnose <- training$diagnosis
View(IL)
IL$diagnosis <- training$diagnosis
View(IL)
rm(IL)
IL<-training[,58:69]
IL$diagnosis <- training$diagnosis
?train
model1<-train(diagnosis~.,data=IL,method='glm')
predict(model1,testing[,58:69])
confusionMatrix(testing$diagnosis,predict(model1,testing[,58:69]))
preProc<-preProcess(IL,method='pca',thresh=0.8,outcome = training$diagnosis)
preProc
preProc<-preProcess(IL,method='pca',thresh=0.8)
preProc
preProc$rotation
trainPC <- predict(preProc,IL)
View(trainPC)
model2<-train(diagnosis~.,method='glm',data=trainPC)
confusionMatrix(testing$diagnosis,predict(model1,testing[,58:69]))
confusionMatrix(testing$diagnosis,predict(model2,testing[,58:69]))
confusionMatrix(testing$diagnosis,predict(model2,predict(preProc,testing[,58:69])))
library(ElemStatLearn)
data(prostate)
str(prostate)
small <- prostate[1:5,]
lm(lpsa~.,data=small)
library(ISLR)
data(Wage)
library(caret)
Wage <- subset(Wage,select=-c(logwage))
inBuild <- createDataPartition(Wage$wage,p=0.7,list=F)
validation <- Wage[-inBuild,]
buildData <- Wage[inBuild,]
inTrain <- createDataPartition(buildData$wage,p=0.7,list=F)
training <- buildData[inTrain,]
testing<-buildD
testing<-buildData[-inTrain,]
mod1 <- train(wage~.,method='glm',data=training)
mod2<-train(wage~.,method='rf',data=training,trControl=trainControl(mrthod='cv'),number=3)
mod2<-train(wage~.,method='rf',data=training,trControl=trainControl(method='cv'),number=3)
pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
combModFit <- train(wage~.,method='gam',data=predDF)
combPred <- predict(combModFit,predDF)
sqrt(sum((pred1-testing$wage)^2))
sqrt(sum((pred2-testing$wage)^2))
sqrt(sum((combPred-testing$wage)^2))
pred1V <- predict(mod1,validation)
pred2V <- predict(mod2,validation)
predVDF <- data.frame(pred1=pred1V,pred2=pred2V)
combPredV <-predict(combModFit,predVDF)
sqrt(sum((pred1V-validation$wage)^2))
sqrt(sum((pred2V-validation$wage)^2))
sqrt(sum((combPredV-validation$wage)^2))
library(quantmod)
from.dat<-as.Date('01/01/08',format='%m%d%y')
to.dat<-as.Date('12/31/13',format='%m%d%y')
getSymbols('GOOG',src='google',from=from.dat,to=to.dat)
getSymbols('GOOG', src='google',from = from.dat, to = to.dat)
from.dat<-as.Date('01/01/08',format='%m/%d/%y')
to.dat<-as.Date('12/31/13',format='%m/%d/%y')
getSymbols('GOOG', src='google',from = from.dat, to = to.dat)
head(GOOG)
View(GOOG)
View(GOOG)
mGoog <- to.monthly(GOOG)
?getSlots
?getSymbols
googOpen <- Op(mGoog)
mGoog <- to.monthly(GOOG)
rm(list=ls())
linrary(quantmod)
library(quantmod)
from.dat <- as.Date('01/01/08', format='%m/%d/%y')
to.dat <- as.Date('12/31/13', format='%m/%d/%y')
getSymbols("GOOG", src='google', from=from.dat,to=to.dat)
head(GOOG)
View(GOOG)
GOOG <- GOOG[,1:4]
mGoog <- to.monthly(GOOG)
googOpen <-Op(mGoog)
ts1 <- ts(googOpen,frequency = 12)
plot(ts1,xlab='Years+1',ylab='GOOG')
?to.monthly
?Op
View(mGoog)
View(GOOG)
View(GOOG)
View(googOpen)
?ts
ts1Train <- window(ts1,start=1,end=5)
ts1Test <- window(ts1,start=5,end=(6.99))
ts1Train
ets1 <- ets(ts1Train,model='MMM')
?ets
?forecast
install.packages("forecast")
ets1 <- ets(ts1Train,model='MMM')
?forecast
library(forecast)
ets1 <- ets(ts1Train,model='MMM')
fcast <- forecast(ets1)
plot(fcast)
lines(ts1Test,col=red)
lines(ts1Test,col='red')
accuracy(fcast,ts1Test)
rm(list=ls())
data(iris)
inTrain <- createDataPartition(iris$Species,p=0.7,list = F)
training <- iris[intrain,]
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
kMeans1 <- kmeans(subset(training,select = -c(Species)),centers=3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
modFit <- train(clusters~.,data=subset(training,select=-c(Species)),methods='rpart')
table(predict(modFit,training),training$Species)
testClusterPred <- predict(modFit,testing)
table(testClusterPred,testing$Species)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
mod1 <- train(y~.,data=vowel.train,method='rf')
mod2 <- train(y~.,data=vowel.train,method='gbm')
View(vowel.train)
View(vowel.train)
mean(predict(mod1,testing)==testing$y)
mean(predict(mod1,vowel.test)==vowel.test$y)
mean(predict(mod2,vowel.test)==vowel.test$y)
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree= mod1==mod2)
pred <- data.frame(mod1, mod2, y=vowel.test$y, agree= mod1==mod2)
pred <- data.frame(mod1, mod2, y=vowel.test$y, agree=(mod1==mod2))
pred <- data.frame(predict(mod1,vowel.test), predict(mod2,vowel.test), y=vowel.test$y, agree=(predict(mod1,vowel.test)==predict(mod2,vowel.test)))
head(pred)
5/6
mean(pred$agree==pred$y[pred$agree])
mean(pred$agree==pred$y)
View(pred)
sum(pred$agree==pred$y[pred$agree])
mean(predict(mod1,vowel.test)$y[pred$agree]==pred$y[pred$agree])
mean(predict(mod1,vowel.test)$y==pred$y)
mean(predict(mod1,vowel.test)==pred$y)
rm(list=ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
mod1 <- train(diagnosis~.,method='rf',data=training)
mod2 <- train(diagnosis~.,method='gbm',data=training)
mod3 <- train(diagnosis~.,method='lda',data=training)
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
predRf <- predict(mod1, testing)
predGBM <- predict(mod2, testing)
predLDA <- predict(mod3, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fit <- train(diagnosis~.,data=pred,method='rf')
predict(fit,testing)
mean(predict(fit,testing)==testing$diagnosis)
mean(predict(mod1,testing)==testing$diagnosis)
mean(predict(mod2,testing)==testing$diagnosis)
mean(predict(mod3,testing)==testing$diagnosis)
mod2
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
View(training)
mod <- train(CompressiveStrength~.,data=training,method='lasso')
?plot.enet
plot.enet(mod)
plot.enet(mod$finalModel)
rm(list=ls())
gaData <- read.csv("/var/folders/cs/h5grb7b119g3y4_wrvvr58r40000gn/T//RtmpqMUddw/data3b42d165ec")
View(gaData)
library(lubridate)  # For year() function below
dat = gaData
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
?bats
mod <- bats(tstrain)
mod
pred <- forecast(fit,level=95,h=dim(testing)[1])
pred <- forecast(mod,level=95,h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing,data.frame(pred))
names(testing)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
prop.table(table(predComb$in95))[2]
View(testing)
View(predComb)
?prop.table
count(predComb$in95==TRUE)
226/235
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
View(training)
mod <- train(CompressiveStrength~.,data=training,method='svm')
mod <- svm(CompressiveStrength~.,data=training)
sum((predict(mod,testing)-testing$CompressiveStrength)^2)
?RMSE
RMSE(predict(mod,testing),testing$CompressiveStrength)
data(yeast)
data(Yeast)
yeast <- read.table("/var/folders/cs/h5grb7b119g3y4_wrvvr58r40000gn/T//RtmpqtUQZ2/data142c57681c7a", quote="\"", comment.char="")
View(yeast)
names(yeast)
names(yeast) <- c('Sequence Name','mcg','gvh','alm','mit','erl','pox','vac','nuc','class')
summary(yeast)
yeast <- yeast[,2:10]
library(caret)
createDataPartition(yeast$class,p=0.7,list=F)
inTrain <- createDataPartition(yeast$class,p=0.7,list=F)
training <- yeast[inTrain,]
test <- yeast[-inTrain,]
hist(training$class)
unique(training$class)
levels(training$class) <- c(1:10)
training$class
levels(yeast$class) <- c(1:10)
training <- yeast[inTrain,]
test <- yeast[-inTrain,]
hist(training$class)
class(training$class)
?numeric
hist(as.numeric(training$class))
hist(as.numeric(test$class))
hist(as.numeric(training$class))
hist(as.numeric(test$class))
nearZeroVar(training[,1:8],saveMetrics = T)
training <- training[,-c(5,6)]
test <- test[,-c(5,6)]
View(training)
mod <- train(training$class~.data=training,method='rf')
mod <- train(training$class~.,data=training,method='rf')
View(training)
confusionMatrix(test$class,predict(mod,test$class))
confusionMatrix(test$class,predict(mod,test$class))
confusionMatrix(test$class,predict(mod,test[1:8]))
confusionMatrix(test$class,predict(mod,test[,1:8]))
confusionMatrix(test$class,predict(mod,test[,1:6]))
mod <- train(training$class~.,data=training,method='rf',preProcess=c('center','scale'))
confusionMatrix(test$class,predict(mod,test[,1:6]))
?randomForest
?confusionMatrix
?preProcess
mod <- train(training$class~.,data=training,method='rf',preProcess=c('BoxCox'))
warnings()
confusionMatrix(test$class,predict(mod,test[,1:6]))
summary(training)
summary(yeast)
confusionMatrix(test$class,predict(mod,test[,1:6]))
library(caret)
confusionMatrix(test$class,predict(mod,test[,1:6]))
nearZeroVar(training,saveMetrics = T)
mod <- train(training$class~.,data=training,method='rf',preProcess='pca')
confusionMatrix(test$class,predict(mod,test[,1:6]))
mod <- train(training$class~.,data=training,method='rf',preProcess='BoxCox')
confusionMatrix(test$class,predict(mod,test[,1:6]))
View(training)
result <- rfcv(training[,1:6],training$class)
result
mod1 <- randomForest(x=training[,1:6],y=training$class,xtest=test[,1:6],ytest=test$class,importance=T)
mod1
mod1 <- randomForest(x=training[,1:6],y=training$class,xtest=test[,1:6],ytest=test$class)
mod1
print(mod1)
mod1.mse
mod1$mtry
mod1$votes
training _exp <- poly(training[,1:6],degree=2,raw=T)
training_exp <- poly(training[,1:6],degree=2,raw=T)
training_exp <- poly(training[,1:6],degree=2,raw=T)
?poly
training_exp <- do.call(poly, c(lapply(training[,1:6])), degree=2,raw=T)
training_exp <- do.call(poly, c(lapply(training[,1:6]), degree=2,raw=T))
training_exp <- do.call(poly, c(lapply(1:6 function(x) training[,x]), degree=2,raw=T))
do.call(poly, c(lapply(1:6 function(x) training[,x]), degree=2,raw=T))
do.call(poly, c(lapply(1:6, function(x) training[,x]), degree=2,raw=T))
training_exp <- do.call(poly, c(lapply(1:6, function(x) training[,x]), degree=2,raw=T))
as.matrix(training_exp,1043,27)
as.data.frame(training_exp)
training_exp <- as.data.frame(training_exp)
View(training_exp)
nearZeroVar(training_exp)
nearZeroVar(training_exp,saveMetrics = T)
test_exp <- do.call(poly, c(lapply(1:6, function(x) test[,x]), degree=2,raw=T))
test_exp <- as.data.frame(test_exp)
mod1 <- randomForest(x=training_exp,y=training$class,xtest=test_exp,ytest=test$class,importance = T)
mod1
rm(list=ls())
setwd("~/Documents/2015Fall/EE660/EE660_Project")
load("~/Documents/2015Fall/EE660/EE660_Project/project_v1.RData")
write.csv(as.data.frame(training_label),'training_label.csv',
row.names = FALSE)
write.csv(as.data.frame(test_label),'test_label.csv',row.names = FALSE)
as.data.frame(training_label)
training_label<-as.data.frame(training_label)
View(training_label)
training_label <- label[inTrain]
write.csv(training_label,'training_label.csv',
row.names = FALSE, col.names = FALSE)
write.csv(as.data.frame(test_label),'test_label.csv',
row.names = FALSE, col.names = FALSE)
write.csv(cbind(training,training_label),'training.csv',row.names = FALSE)
write.csv(cbind(test,test_model),'test.csv',row.names = FALSE)
write.csv(cbind(test,test_label),'test.csv',row.names = FALSE)
load("~/Documents/2015Fall/EE660/EE660_Project/project_v1.RData")
nlevels(training_label)
