---
title: "Data Mining for Diabetes Readmission Prediction"
author: 
- "Siyuan Meng"
- 'siyuanme@usc.edu'
date: "December 8, 2015"
output: 
  pdf_document: 
    keep_tex: yes
---
# Reproducibility
In order to get the same results, need certain set of packages, as well as setting a pseudo-random seed equal the one I used.

* The following libraries were used for this project:

```{r Loading packages}
library(caret)
library(randomForest)
library(pander)
```

* Here is the seed I set to generate pseudo-random numbers for spliting training and test dataset. (see `Preprocessing` section)
```{r setseed}
set.seed(12345)
```

# Getting data

```{r Import dataset, cache=TRUE}
setwd("~/Documents/2015Fall/EE660/EE660_Project")
data <- read.csv("~/Documents/2015Fall/EE660/EE660_Project/diabetic_data.csv",
                 stringsAsFactors=T,na.strings = '?')
dim(data)
```

# Cleaning data

The original missing value information can be found in http://www.hindawi.com/journals/bmri/2014/781670/tab1/. For simplicity, only show features which have missing values. (cite)

```{r missingvalues, echo=FALSE}
NA_information <- data.frame(Feature_name=c(1:5),Type=c(1:5),Discription=c(1:5), Propotional_missing=c(1:5))
NA_information$Feature_name <- c('Race','Weight','Payer code','Medical specialty','Diagnosis 3')
NA_information$Type <- c('Nominal','Numeric','Nominal','Nominal','Nominal')
NA_information$Discription <- c('Values: Caucasian, Asian, African American, Hispanic, and other','Weight in pounds','Integer identifier corresponding to 23 distinct values, 
                                for example, Blue Cross/Blue Shield, Medicare, and self-pay','Integer identifier of a specialty of the admitting physician,
                                corresponding to 84 distinct values','Additional secondary diagnosis (coded as first three digits of ICD9),
                                corresponding to 954 distinct values')
NA_information$Propotional_missing <- c('2%','97%','40%','50%','1%')
pander(NA_information)
```

The way I deal with missing values is to delete `Weight`, `Payer code` feaures (columns), since both features have more than 50% missing values and they are not relevant to classification. However, `Medical speciality` was maintained, adding the value “missing” in order to account for missing values. (cite) 

```{r deleteNA}
data <- data[,c(-6,-11)]
data$medical_specialty <- factor(data$medical_specialty,
                levels=c(levels(data$medical_specialty),'Missing'))
data[,10][is.na(data$medical_specialty)] <- 'Missing'
data <- na.omit(data)
dim(data)
```

In general, should split the original data into training and testing first and then deal with the missing values. However, both methods will yield same dimension of `data`. For simplicity, deal with NAs first here.

# Preprocessing
(Preprocessing is more crucial when using model based algorithms, e.g. Linear Discrimant Analysis, Naive Bayes, Linear Regression...than using non-parametrical algorithms.)

* There are also other ways to impute data, like knnimpute...For convenience, try omitting NA rows first.

* The data has been preprocessed to ensure each encounter has a unique id. However, each patient may have more than one id.

```{r checkunique}
length(unique(data$encounter_id))
length(unique(data$patient_nbr))
```

We thus used only one encounter per patient; in particular, we considered only the first encounter for each patient as the primary admission and determined whether or not they were readmitted within 30 days. (cite)

```{r makeunique}
data <- data[order(data[,2]),]
unique_list <- array(TRUE,nrow(data))
for (l in 2:nrow(data)){
    if (data[l,'patient_nbr']==data[l-1,'patient_nbr']){
        unique_list[l]=FALSE
    }
}
data <- subset(data,unique_list)
```

* Kill the first two features(`encounter_id` and `patient_nbr`) which are ids for encounted and patients. Also, kill near zero variables, since they are not considered relevant to the outcome. Besides, extract label column, which is the last column of `data`.

```{r killfirsttwo}
data <- data[,c(-1,-2)]
label <- data$readmitted
data <- data[,-46]
```

* Split this train data into training and test dataset according to the ratio 6:4 (set seed to make partioning reproducible)
(Here I don't split validation since without looking data, there is possibility that test and training may not have the same distribution of different classes. Using cross validation is better in this case, though the computational complexity is high.)

```{r Preprocessing_splitting, cache=TRUE}
inTrain <- createDataPartition(label,p=0.8,list=FALSE)
training <- data[inTrain,]
training_label <- label[inTrain]
test <- data[-inTrain,]
test_label <- label[-inTrain]
```

* Now, let's see if samples of different classes of `training` dataset are unbalanced.

```{r Preprocessing_classtype}
par(cex=0.7,pin=c(4,3))
plot((training_label), xlab = 'Days to inpatient readmission', ylab = 'frequency',
     col = 'red', main = 'Histogram of different classes')
```

Classes are unbalanced distributed, but not very skewed.

* Kill unimportant features.(_nearZeroVar_ diagnoses predictors that have one unique value (i.e. are zero variance predictors) or predictors that are have both of the following characteristics: they have very few unique values relative to the number of samples and the ratio of the frequency of the most common value to the frequency of the second most common value is large.) (cite)

```{r Preprocessing_feature_statistics,cache=TRUE}
NZV <- nearZeroVar(training,saveMetrics = T,freqCut=98/2)
training <- training[,-which(NZV$nzv==TRUE)]
```

* Kill same features for `test` dataset without looking inside.

```{r killfeatures_test}
test <- test[,-which(NZV$nzv==TRUE)]
```

* Use background information for all features to analyze which features should be converted to numerical features. (cite)
* Note: Need to combine training and test to a big dataset and then convert to numerical fearutes. If convert seperately, some feature may have some level which has only few points and are all assigned into `training` or `test` dataset. This may lead to different dimensions for `training` and `test` dataset after conversion.

```{r Preprocessing_C2N, cache=TRUE}
source('~/Documents/2015Fall/EE660/EE660_Project/C2N.R')
data <- rbind(training,test)
for (i in c(1:6,8,15:17,19:29)){
    temp <- as.factor(data[,i])
    data <- cbind(data,C2N(temp))
}
data <- data[,-c(1:6,8,15:17,19:29)]
training <- data[1:length(training_label),]
test <- data[(length(training_label)+1):68630,]
```

* Again, kill unimportant features using _nearZeroVar_.
```{r nzv2,cache=TRUE}
NZV_2 <- nearZeroVar(training,saveMetrics = T,freqCut=98/2)
training <- training[,-which(NZV_2$nzv==TRUE)]
test<- test[,-which(NZV_2$nzv==TRUE)]
```

* Normalize data (tried different methods, just write the best one I found here)
```{r normalization}
training <- apply(training,2,as.numeric)
test <- apply(test,2,as.numeric)
training_std <- apply(training,2,function(x) x/sum(x))
test_std <- apply(test,2,function(x) x/sum(x))
```

# Save `training` and `test` into csv file for future use

```{r savecsv}
write.csv(cbind(training_std,training_label),'training.csv',row.names = FALSE)
write.csv(cbind(test_std,test_label),'test.csv',row.names = FALSE)
```

Purpose for doing that is `R` is good for exploratory research, but not good at dealing with large dataset for clasification. Use `Python` to read csv as `SFrame` for classification will speed up! (cite)

